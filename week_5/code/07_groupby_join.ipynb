{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = spark.read.parquet('data/pq/green/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green.registerTempTable('green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    -- Reveneue grouping \n",
    "    date_trunc('hour', lpep_pickup_datetime) AS hour, \n",
    "    PULocationID AS zone,\n",
    "\n",
    "    -- Revenue calculation \n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "\n",
    "FROM green\n",
    "WHERE lpep_pickup_datetime >= '2020-01-01 00:00:00'\n",
    "GROUP BY 1, 2\n",
    "ORDER BY 1,2    \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+--------------+\n",
      "|               hour|zone|            amount|number_records|\n",
      "+-------------------+----+------------------+--------------+\n",
      "|2020-01-01 00:00:00|   7| 368.7800000000001|            18|\n",
      "|2020-01-01 00:00:00|  16|              20.3|             1|\n",
      "|2020-01-01 00:00:00|  17|58.300000000000004|             3|\n",
      "|2020-01-01 00:00:00|  25|               7.2|             1|\n",
      "|2020-01-01 00:00:00|  31|             23.34|             1|\n",
      "|2020-01-01 00:00:00|  35|109.27000000000001|             2|\n",
      "|2020-01-01 00:00:00|  36|            144.93|             8|\n",
      "|2020-01-01 00:00:00|  37|160.89000000000001|             5|\n",
      "|2020-01-01 00:00:00|  39|             66.22|             2|\n",
      "|2020-01-01 00:00:00|  40|              13.8|             1|\n",
      "|2020-01-01 00:00:00|  41|             50.45|             4|\n",
      "|2020-01-01 00:00:00|  42| 94.16999999999999|            10|\n",
      "|2020-01-01 00:00:00|  56|              8.84|             1|\n",
      "|2020-01-01 00:00:00|  61|             28.05|             4|\n",
      "|2020-01-01 00:00:00|  74|             83.68|             7|\n",
      "|2020-01-01 00:00:00|  75|14.870000000000001|             2|\n",
      "|2020-01-01 00:00:00|  77|              16.8|             1|\n",
      "|2020-01-01 00:00:00|  78|               7.8|             1|\n",
      "|2020-01-01 00:00:00|  80|1199.8799999999999|            36|\n",
      "|2020-01-01 00:00:00|  82|            191.86|            16|\n",
      "+-------------------+----+------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green_revenue.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue \\\n",
    "    .repartition(20) \\\n",
    "    .write.parquet('data/report/revenue/green', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = spark.read.parquet('data/pq/yellow/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow.registerTempTable('yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow_revenue = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    -- Reveneue grouping \n",
    "    date_trunc('hour', tpep_pickup_datetime) AS hour, \n",
    "    PULocationID AS zone,\n",
    "\n",
    "    -- Revenue calculation \n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "\n",
    "FROM yellow\n",
    "WHERE tpep_pickup_datetime >= '2020-01-01 00:00:00'\n",
    "GROUP BY 1, 2\n",
    "ORDER BY 1,2    \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow_revenue \\\n",
    "    .repartition(20) \\\n",
    "    .write.parquet('data/report/revenue/yellow', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Green + Yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue = spark.read.parquet('data/report/revenue/green')\n",
    "df_yellow_revenue = spark.read.parquet('data/report/revenue/yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue_tmp = df_green_revenue \\\n",
    "    .withColumnRenamed('amount', 'green_amount') \\\n",
    "    .withColumnRenamed('number_records', 'green_number_records')\n",
    "\n",
    "df_yellow_revenue_tmp = df_yellow_revenue \\\n",
    "    .withColumnRenamed('amount', 'yellow_amount') \\\n",
    "    .withColumnRenamed('number_records', 'yellow_number_records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_green_revenue_tmp.join(df_yellow_revenue_tmp, on=['hour', 'zone'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------+--------------------+------------------+---------------------+\n",
      "|               hour|zone|green_amount|green_number_records|     yellow_amount|yellow_number_records|\n",
      "+-------------------+----+------------+--------------------+------------------+---------------------+\n",
      "|2020-01-01 00:00:00|   4|        null|                null|            499.22|                   27|\n",
      "|2020-01-01 00:00:00|  26|        null|                null|               3.8|                    1|\n",
      "|2020-01-01 00:00:00|  56|        8.84|                   1|             73.67|                    1|\n",
      "|2020-01-01 00:00:00|  61|       28.05|                   4|             18.76|                    2|\n",
      "|2020-01-01 00:00:00|  65|        null|                null|            113.66|                    5|\n",
      "|2020-01-01 00:00:00|  74|       83.68|                   7|            279.88|                   24|\n",
      "|2020-01-01 00:00:00|  88|        null|                null|117.30000000000001|                    6|\n",
      "|2020-01-01 00:00:00| 114|        null|                null| 720.7500000000002|                   43|\n",
      "|2020-01-01 00:00:00| 116|        null|                null|171.99999999999997|                   11|\n",
      "|2020-01-01 00:00:00| 159|        30.6|                   2|              null|                 null|\n",
      "|2020-01-01 00:00:00| 189|        null|                null|              11.3|                    1|\n",
      "|2020-01-01 00:00:00| 216|       44.38|                   2|              null|                 null|\n",
      "|2020-01-01 00:00:00| 230|        null|                null| 2375.839999999999|                   98|\n",
      "|2020-01-01 00:00:00| 233|        null|                null|385.40000000000003|                   18|\n",
      "|2020-01-01 00:00:00| 247|        35.4|                   3|               8.8|                    1|\n",
      "|2020-01-01 00:00:00| 249|        null|                null|1459.5499999999997|                   58|\n",
      "|2020-01-01 00:00:00| 255|       96.35|                   4|            104.43|                    8|\n",
      "|2020-01-01 00:00:00| 262|        null|                null|338.59000000000003|                   18|\n",
      "|2020-01-01 01:00:00|  39|        35.3|                   1|              null|                 null|\n",
      "|2020-01-01 01:00:00|  51|       81.12|                   2|              null|                 null|\n",
      "+-------------------+----+------------+--------------------+------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.write.parquet('data/report/revenue/total', mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = spark.read.parquet('data/report/revenue/total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+--------------------+------------------+---------------------+\n",
      "|               hour|zone|      green_amount|green_number_records|     yellow_amount|yellow_number_records|\n",
      "+-------------------+----+------------------+--------------------+------------------+---------------------+\n",
      "|2020-01-01 00:00:00|  22|              null|                null|               0.0|                    2|\n",
      "|2020-01-01 00:00:00|  35|109.27000000000001|                   2|             15.75|                    1|\n",
      "|2020-01-01 00:00:00|  40|              13.8|                   1|             25.86|                    3|\n",
      "|2020-01-01 00:00:00|  43|              null|                null|387.55000000000007|                   19|\n",
      "|2020-01-01 00:00:00|  70|              null|                null|               9.8|                    1|\n",
      "|2020-01-01 00:00:00|  76|              null|                null|             75.81|                    2|\n",
      "|2020-01-01 00:00:00|  77|              16.8|                   1|              null|                 null|\n",
      "|2020-01-01 00:00:00|  79|              null|                null| 4070.989999999996|                  230|\n",
      "|2020-01-01 00:00:00|  83|             26.29|                   2|253.33999999999997|                   10|\n",
      "|2020-01-01 00:00:00|  90|              null|                null|           1274.69|                   65|\n",
      "|2020-01-01 00:00:00| 112|            117.41|                   8|            166.82|                   10|\n",
      "|2020-01-01 00:00:00| 119|              13.3|                   1|             84.25|                    3|\n",
      "|2020-01-01 00:00:00| 127|              null|                null|107.97999999999999|                    4|\n",
      "|2020-01-01 00:00:00| 136|              19.3|                   1|              null|                 null|\n",
      "|2020-01-01 00:00:00| 145|              null|                null| 60.75999999999999|                    4|\n",
      "|2020-01-01 00:00:00| 193|              null|                null|             32.76|                    7|\n",
      "|2020-01-01 00:00:00| 197|              null|                null|             42.83|                    1|\n",
      "|2020-01-01 00:00:00| 222|             78.59|                   2|              null|                 null|\n",
      "|2020-01-01 00:00:00| 243|              16.3|                   1|119.99999999999999|                    7|\n",
      "|2020-01-01 01:00:00|  33|              null|                null|             18.96|                    1|\n",
      "+-------------------+----+------------------+--------------------+------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.parquet('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_join.join(df_zones, df_join.zone == df_zones.LocationID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.drop('LocationId', 'zone').write.parquet('tmp/revenue-zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
